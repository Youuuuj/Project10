---
title: "개와 고양이 분류분석"
author: "오준서(조장), 이순규, 한호종, 유준"
date: '2022 - 02 - 14'
output: 
  html_document :
    toc : true
    toc_float : true
    theme : united
---

<style>
#TOC{top:20%;}
</style>


```{r, include=FALSE}
library(keras)
```

***

# 목표

주어진 사진들로 분류문제를 실행하고, 시각화한다.

또한, 분류 정확성을 높이기위한 방법과 사용자가 조정할 수 있는 파라미터가 무엇인지 알아보도록 하겠다.

***

# 고양이와 개의 사진 분류분석
### 교육, 검증 및 테스트 디렉토리에 이미지 복사
```{r, results='hide'}
original_dataset_dir <- "C:\\Users\\You\\Downloads\\dogs-vs-cats\\train"
base_dir <- "C:\\Users\\You\\Downloads\\dogs-vs-cats\\result"
dir.create(base_dir)
```

***

### 학습,검증,테스트 경로 생성
```{r, results='hide'}
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
train_cats_dir <- file.path(train_dir, "cats")
train_dogs_dir <- file.path(train_dir, "dogs")
validation_cats_dir <- file.path(validation_dir, "cats")
validation_dogs_dir <- file.path(validation_dir, "dogs")
test_cats_dir <- file.path(test_dir, "cats")
test_dogs_dir <- file.path(test_dir, "dogs")
```

***

### 파일 생성
```{r, results='hide'}
a <- c(train_dir,test_dir,validation_dir,train_cats_dir,train_dogs_dir,
       validation_cats_dir,validation_dogs_dir,test_cats_dir,test_dogs_dir)
lapply(a,dir.create)
```

***

### 개와 고양이 이미지 분류
```{r, results='hide'}
fnames <- paste0("cat.", 2001:3000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames), 
          file.path(train_cats_dir)) 

fnames <- paste0("cat.", 3001:3500, ".jpg")
file.copy(file.path(original_dataset_dir, fnames), 
          file.path(validation_cats_dir))

fnames <- paste0("cat.", 3501:4000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(test_cats_dir))

fnames <- paste0("dog.", 4001:5000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(train_dogs_dir))

fnames <- paste0("dog.", 5001:5500, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(validation_dogs_dir)) 

fnames <- paste0("dog.", 5501:6000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(test_dogs_dir))

```


***

### 분류 데이터 개수 확인

```{r, results='hide'}
cat("total training cat images:", length(list.files(train_cats_dir)), "\n")
cat("total training dog images:", length(list.files(train_dogs_dir)), "\n")
cat("total validation cat images:", length(list.files(validation_cats_dir)), "\n")
cat("total validation dog images:", length(list.files(validation_dogs_dir)), "\n")
cat("total test cat images:", length(list.files(test_cats_dir)), "\n")
cat("total test dog images:", length(list.files(test_dogs_dir)), "\n")
```

개와 고양이 사진을 train,validation,test image로 분류했으며 동일한 비율로 나뉜 것을 확인한다.

***


### model 파라미터 값 설정 
```{r, results='hide'}
model <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

summary(model)
```

filter 옵션은 filter의 개수를 정한다.

layer_max_polling_2d 함수는 사소한 변화를 무시할 수 있게 해준다.

무의미한 변화까지 모두 잡아내게 되면 시간도 오래 걸리고 정확도 또한 떨어질 것이다.

여기서는 pool size를 (2,2)로 설정했기 때문에 출력 사진 크기는 입력 사진 크기의 반으로 줄어든다.

각 층의 kernel_size는 (3,3)로 동일하며 convolution filter의 사이즈를 결정한다.

여기서, activation은 대표적으로 다음과 같은 옵션들이 있다.

‘linear’ : 입력뉴런과 가중치로 계산된 결과값이 그대로 출력으로 나옵니다.

‘relu’ : rectifier 함수, 은닉층에 주로 쓰입니다.

‘sigmoid’ : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰입니다.

‘softmax’ : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다.

코드를 살펴보면 출력 직전까진 은닉층에 relu를 썻지만 최종적으로 결과를 출력할 땐
이진분류에 주로 사용하는 sigmoid 함수를 적용한 것을 볼 수 있다.

***

### 학습을 위한 모델 구성
```{r, results='hide'}
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(learning_rate = 1e-4),
  metrics = c("acc")
)
```

***


### 이미지 사이즈 조정 및 데이터 타입 변경
```{r, results='hide'}
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  train_dir,
  train_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
```

Keras는 네트워크에 데이터를 가져오는 과정을 처리할 수 있는 기능이 존재한다.

keras에는 여러 이미지 처리도우미 도구가 포함되어 있으며, 

'image_data_generator()'함수가 포함되어 있어 디스크의 이미지 파일을 사전 처리된 tensor 배치로 자동전환 할 수 있다. 

이 함수를 사용하여 디렉토리에서 이미지를 읽어올 것이다. 

***


### 배치 생성기를 사용하여 모델 피팅
```{r, results='hide'}
batch <- generator_next(train_generator)
str(batch)

history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 30,
  validation_data = validation_generator,
  validation_steps = 50
)

```

딥러닝 모델을 통해 이항분류를 하고자 할 때, epoch의 수와 steps의 수를 데이터의 사이즈에 맞게 최적화 해주어야 정확한 예측을 할 수 있다.

steps_per_epoch와 validation_steps의 최적값을 구하기 위해서는 전체 데이터 수와 위에서 지정한 batch_size에 주목해야한다.

train 전체데이터수 : 2000 

vaild 전체데이터수 : 1000

배치사이즈 : 20 (batch_size)

전체train / 배치사이즈  =  100 (steps_per_epoch)

전체vaild / 배치사이즈  =  50 (validation_steps)

너무 적은 steps 수를 설정하면 무의미한 반복에 그칠 수 있고,너무 많은 steps 수를 설정하면 모델이 작동하지 않는다.


***


### 모델 저장
```{r, results='hide'}
model %>% save_model_hdf5("cats_and_dogs_small_1.h5")
```

h5형식의 확장자는 대용량의 파일을 효과적으로 저장할 수 있게 해준다.

***

### 시각화
```{r, results='hide'}
plot(history)
```

학습 중 학습 및 검증 데이터에 대한 모델의 손실과 정확도를 그래프로 나타내었다. 

### 시각화 설명

위의 그래프는 과대 적합의 특성이다.

dog-vs-cat 데이터에서 훈련 데이터 정확도는 시간이 지남에 따라 거의 100%에 이를 때까지 선형적으로 증가하는 반면, 검증 데이터 정확도는 75-77%에 머물고 있다.

검증 손실은 15개의  epochs를 지난 후 최소치에 도달했다가 중단되는 반면, 훈련 손실은 거의 0에 도달할 때까지 선형으로 감소한다.

<br><br>
아래는 과대적합을 해결하기 위한 과정이다.

***

### 데이터 보강 구상 설정
```{r, results='hide'}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
```

rotation_range는 랜덤하게 사진을 회전시킬 각도 범위 (0-180 사이)

width_shift_range와 height_shift_range는 사진을 수평과 수직으로 랜덤하게 평행 이동시킬 범위(전체 넓이와 높이에 대한 비율)

shear_range는 랜덤하게 전단 변환을 적용할 각도 범위

zoom_range는 랜덤하게 사진을 확대할 범위

horizontal_flip은 랜덤하게 이미지를 수평으로 뒤집는다. 수평 대칭을 가정할 수 있을 때 사용한다(예를 들어, 풍경/인물 사진)

fill_mode는 이미지가 회전이나 가로/세로 이동으로 인해 비어버린 공간을 새롭게 채울 방법

***

### 무작위로 보강된 훈련 이미지 표시
```{r, results='hide'}
fnames <- list.files(train_cats_dir, full.names = TRUE)
img_path <- fnames[[3]]

img <- image_load(img_path, target_size = c(150, 150))
img_array <- image_to_array(img)
img_array <- array_reshape(img_array, c(1, 150, 150, 3))

augmentation_generator <- flow_images_from_data(
  img_array,
  generator = datagen, 
  batch_size = 1
)

op <- par(mfrow = c(2, 2), pty = "s", mar = c(1, 0, 1, 0))
for (i in 1:4) {
  batch <- generator_next(augmentation_generator)
  plot(as.raster(batch[1,,,]))
}
par(op)

```

***

### 드롭아웃을 포함하는 새 convnet 정의
```{r, results='hide'}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc")
)

```

데이터 증식을 사용하여 늘려도 적은 수의 원본 이미지에서 만들어졌기 때문에 여전히 입력 데이터들 사이에 상호 연관성이 크다.

즉, 새로운 정보를 만들어낼 수 없고 단지 기존 정보의 재조합만 가능하기 때문에 완전히 과대적합을 제거하기에 충분하지 않을 수 있다.

과대적합을 더 억제하기 위해 완전 연결 분류기 직전에 layer_dropout(rate = 0.5) 층을 추가한다.

***

### 데이터 증대 생성기를 사용하여 convnet 훈련
```{r, results='hide'}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
  train_dir, 
  datagen, 
  target_size = c(150, 150), 
  batch_size = 32, 
  class_mode = "binary"
)
validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)
history1 <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 62,
  epochs = 50,
  validation_data = validation_generator,
  validation_steps = 31
)

```


***

### 모델 저장 및 시각화
```{r, results='hide'}
model %>% save_model_hdf5("cats_and_dogs_small_2.h5")

plot(history1)


```

***

# 결론
<mark>분류 정확도를 올리기 위한 방법</mark>으로는 데이터 증강 기법, 특징 추출 기법, 미세 조정 기법이 있다.

데이터 증강(Data Augmentation)은 적은 양의 데이터를 바탕으로 다양한 알고리즘을 통해 데이터의 양을 늘리는 기술이다.

현실 문제를 해결하기 위해 기계학습 및 딥 러닝 기법을 사용하는 경우, 데이터 셋이 부족한 경우가 많다. 

데이터의 부족은 모델 학습 시, 데이터 셋의 특징을 잘 반영하지 못하는 것 이외에도 과소적합 및 과적합에 빠질 위험이 크기 때문에 이를 보완하기 위한 방법이다.

이곳에서는 image_data_generator() 함수와 layer_dropout(rate = 0.5) 함수를 사용했다.



특징 추출(feature extraction)은 머신 러닝에서 컴퓨터가 스스로 학습하기 위해, 입력된 데이터를 분석하여 일정 패턴이나 규칙을 찾아내려면 사람이인지하는 데이터를 컴퓨터가 인지할 수 있는 데이터로 변환해주어야 한다. 

데이터별로 갖고 있는 특징을 찾아내고 여러 특징 중 어떤 특징을 추출할 것인지 결정하는 기법이다.

application_vgg16() 함수와  conv_base %>% predict() 함수,  freeze_weights(conv_base) 함수를 이용한다.



미세 조정(fine tuning)은 특성 추출 기법에서 더 나아가 사전 훈련된 모델과 합성곱층, 데이터 분류기의 가중치를 업데이트하여 훈련시키는 방식이다.

특성 추출은 목표 특성을 잘 추출했다는 전제하에 좋은 성능을 낼 수 있다.

만약 특성이 잘못 추출되었다면 미세 조정 기법으로 새로운 이미지 데이터를 사용하여 네트워크의 가중치를 업데이트해서 특성을 다시 추출할 수 있다. 

즉, 사전 학습된 모델을 목적에 맞게 재학습시키거나 학습된 가중치의 일부를 재학습시키는 것이다.

unfreeze_weights(conv_base, from = "block3_conv1") 함수를 이용한다.

***

# 참조

[참고서적 1 ](https://codebaragi23.github.io/books/DeepLearningFromKeras/Part2/Chapter5/5.2/)
[참고서적 2 ](https://codebaragi23.github.io/books/DeepLearningFromKeras/Part2/Chapter5/5.3/)
[데이터 증강](https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=DIKO0015530517&dbt=DIKO)
[특징 추출](http://www.tcpschool.com/deep2018/deep2018_machine_learning)
[미세 조정](https://thebook.io/080263/ch05/03/02/)
[layer 옵션 설명](https://tykimos.github.io/2017/01/27/CNN_Layer_Talk/)