---
title: "개와 고양이"
author: "오준서(조장), 이순규, 한호종, 유준"
date: '2022 - 02 - 14'
output: 
  html_document :
    toc : true
    toc_float : true
    theme : united
---

<style>
#TOC{top:20%;}
</style>


```{r, include=FALSE}
library(keras)
```

***

주어진 사진들로 분류문제를 실행하고, 시각화한다.
또한, 분류 정확성을 높이기위한 방법과 사용자가 조정할 수 있는 파라미터가 무엇인지 알아보도록 하겠다.

***


# 데이터 가져오기

### 교육, 검증 및 테스트 디렉토리에 이미지 복사
```{r, results='hide'}
original_dataset_dir <- "C:\\Users\\You\\Downloads\\dogs-vs-cats\\train"
base_dir <- "C:\\Users\\You\\Downloads\\dogs-vs-cats\\result"
dir.create(base_dir)
```

***

### 학습,검증,테스트 경로 생성
```{r, results='hide'}
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")
train_cats_dir <- file.path(train_dir, "cats")
train_dogs_dir <- file.path(train_dir, "dogs")
validation_cats_dir <- file.path(validation_dir, "cats")
validation_dogs_dir <- file.path(validation_dir, "dogs")
test_cats_dir <- file.path(test_dir, "cats")
test_dogs_dir <- file.path(test_dir, "dogs")
```

***

### 파일 생성 뭉치기
```{r, results='hide'}
a <- c(train_dir,test_dir,validation_dir,train_cats_dir,train_dogs_dir,
       validation_cats_dir,validation_dogs_dir,test_cats_dir,test_dogs_dir)
lapply(a,dir.create)
```

***

### 설정값 이미지파일 각각 분류
```{r, results='hide'}
fnames <- paste0("cat.", 2001:3000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames), 
          file.path(train_cats_dir)) 

fnames <- paste0("cat.", 3001:3500, ".jpg")
file.copy(file.path(original_dataset_dir, fnames), 
          file.path(validation_cats_dir))

fnames <- paste0("cat.", 3501:4000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(test_cats_dir))

fnames <- paste0("dog.", 4001:5000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(train_dogs_dir))

fnames <- paste0("dog.", 5001:5500, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(validation_dogs_dir)) 

fnames <- paste0("dog.", 5501:6000, ".jpg")
file.copy(file.path(original_dataset_dir, fnames),
          file.path(test_dogs_dir))

```

***


### 분류 데이터 개수 확인

```{r, results='hide'}
cat("total training cat images:", length(list.files(train_cats_dir)), "\n")
cat("total training dog images:", length(list.files(train_dogs_dir)), "\n")
cat("total validation cat images:", length(list.files(validation_cats_dir)), "\n")
cat("total validation dog images:", length(list.files(validation_dogs_dir)), "\n")
cat("total test cat images:", length(list.files(test_cats_dir)), "\n")
cat("total test dog images:", length(list.files(test_dogs_dir)), "\n")
```

***


### model 파라미터 값 설정 
```{r, results='hide'}
model <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, kernel_size = c(4, 4), activation = "relu",
                input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(4, 4), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(4, 4), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(4, 4), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")

summary(model)
```

***

### 학습을 위한 모델 구성
```{r, results='hide'}
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc")
)
```

***


### 이미지 사이즈 조정 및 데이터 타입 변경

```{r, results='hide'}
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  train_dir,
  train_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary"
)
```

***


### 배치 생성기를 사용하여 모델 피팅
```{r, results='hide'}
batch <- generator_next(train_generator)
str(batch)

history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 30,
  validation_data = validation_generator,
  validation_steps = 50
)

```


***


### 모델 저장
```{r, results='hide'}
model %>% save_model_hdf5("cats_and_dogs_small_1.h5")
```

***

### 시각화
```{r, results='hide'}
plot(history)
```


***

### 데이터 보강 구상 설정
```{r, results='hide'}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
```

rotation_range는 랜덤하게 사진을 회전시킬 각도 범위 (0-180 사이)
width_shift_range와 height_shift_range는 사진을 수평과 수직으로 랜덤하게 평행 이동시킬 범위(전체 넓이와 높이에 대한 비율)
shear_range는 랜덤하게 전단 변환을 적용할 각도 범위
zoom_range는 랜덤하게 사진을 확대할 범위
horizontal_flip은 랜덤하게 이미지를 수평으로 뒤집는다. 수평 대칭을 가정할 수 있을 때 사용한다(예를 들어, 풍경/인물 사진)
fill_mode는 이미지가 회전이나 가로/세로 이동으로 인해 비어버린 공간을 새롭게 채울 방법


***


### 무작위로 보강된 훈련 이미지 표시
```{r, results='hide'}
fnames <- list.files(train_cats_dir, full.names = TRUE)
img_path <- fnames[[3]]

img <- image_load(img_path, target_size = c(150, 150))
img_array <- image_to_array(img)
img_array <- array_reshape(img_array, c(1, 150, 150, 3))

augmentation_generator <- flow_images_from_data(
  img_array,
  generator = datagen, 
  batch_size = 1
)

op <- par(mfrow = c(2, 2), pty = "s", mar = c(1, 0, 1, 0))
for (i in 1:4) {
  batch <- generator_next(augmentation_generator)
  plot(as.raster(batch[1,,,]))
}
par(op)

```



***


### 드롭아웃을 포함하는 새 convnet 정의
```{r, results='hide'}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc")
)

```

데이터 증식을 사용하여 늘려도 적은 수의 원본 이미지에서 만들어졌기 때문에 여전히 입력 데이터들 사이에 상호 연관성이 크다. 즉, 새로운 정보를 만들어낼 수 없고 단지 기존 정보의 재조합만 가능하기 때문에 완전히 과대적합을 제거하기에 충분하지 않을 수 있다. 과대적합을 더 억제하기 위해 완전 연결 분류기 직전에 layer_dropout(rate = 0.5) 층을 추가한다.

***


### 데이터 증대 생성기를 사용하여 convnet 훈련
```{r, results='hide'}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
  train_dir, 
  datagen, 
  target_size = c(150, 150), 
  batch_size = 32, 
  class_mode = "binary"
)
validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)
history1 <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 100,
  validation_data = validation_generator,
  validation_steps = 50
)

```

***


### 모델 저장 밑 시각화
```{r, results='hide'}
model %>% save_model_hdf5("cats_and_dogs_small_2.h5")

plot(history1)


```

***

### 결론

분류 정확도를 올리기 위한 방법으로는 데이터 증강 기법, 특징 추출 기법, 미세 조정 기법이 있다.

데이터 증강(Data Augmentation)은 적은 양의 데이터를 바탕으로 다양한 알고리즘을 통해 데이터의 양을 늘리는 기술이다. 현실 문제를 해결하기 위해 기계학습 및 딥 러닝 기법을 사용하는 경우, 데이터 셋이 부족한 경우가 많다. 데이터의 부족은 모델 학습 시, 데이터 셋의 특징을 잘 반영하지 못하는 것 이외에도 과소적합 및 과적합에 빠질 위험이 크기 때문에 이를 보완하기 위한 방법이다.
이곳에서는 image_data_generator() 함수와 layer_dropout(rate = 0.5) 함수를 사용했다.

특징 추출(feature extraction)은 머신 러닝에서 컴퓨터가 스스로 학습하기 위해, 입력된 데이터를 분석하여 일정 패턴이나 규칙을 찾아내려면 사람이
인지하는 데이터를 컴퓨터가 인지할 수 있는 데이터로 변환해주어야 한다. 데이터별로 갖고 있는 특징을 찾아내고 여러 특징 중 어떤 특징을 추출할 것인지 결정하는 기법이다.
application_vgg16() 함수와  conv_base %>% predict() 함수,  freeze_weights(conv_base) 함수를 이용한다.

미세 조정(fine tuning)은 특성 추출 기법에서 더 나아가 사전 훈련된 모델과 합성곱층, 데이터 분류기의 가중치를 업데이트하여 훈련시키는 방식이다. 특성 추출은 목표 특성을 잘 추출했다는 전제하에 좋은 성능을 낼 수 있다. 만약 특성이 잘못 추출되었다면 미세 조정 기법으로 새로운 이미지 데이터를 사용하여 네트워크의 가중치를 업데이트해서 특성을 다시 추출할 수 있다. 즉, 사전 학습된 모델을 목적에 맞게 재학습시키거나 학습된 가중치의 일부를 재학습시키는 것이다.
unfreeze_weights(conv_base, from = "block3_conv1") 함수를 이용한다.

***

### 참조

https://codebaragi23.github.io/books/DeepLearningFromKeras/Part2/Chapter5/5.2/
https://codebaragi23.github.io/books/DeepLearningFromKeras/Part2/Chapter5/5.3/

데이터 증강 : https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=DIKO0015530517&dbt=DIKO
특징 추출 : http://www.tcpschool.com/deep2018/deep2018_machine_learning
미세 조정 : https://thebook.io/080263/ch05/03/02/